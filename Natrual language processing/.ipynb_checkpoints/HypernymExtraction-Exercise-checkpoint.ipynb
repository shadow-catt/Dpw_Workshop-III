{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypernym Relationship Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use NLTK and Hearst Pattern for hypernym relationship extraction. \n",
    "- Firstly, install python environment\n",
    "- Install NLTK: pip install nltk\n",
    "- Download data distribution for NLTK. Install using NLTK downloader: ``nltk.download()``. If cannot download using ``nltk.download()``, try download manually from https://github.com/nltk/nltk_data/tree/gh-pages![image.png](attachment:image.png) or https://pan.baidu.com/s/1wONWpaa86_wnsIksKda8eQ (code:tfon )\n",
    "- Unzip the downloaded file to the following folder: ``nltk.data.find(\".\")``\n",
    "- Unzip each zip file in the ten folders: *chunkers, corpora, grammers, help, misc, models, sentiment, stemmers, taggers, tokenizers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyponym Extraction using Hearst Pattern\n",
    "Hyponym extraction follows the following 4 steps:\n",
    "- Noun phrase chunking or named eneity chunking. You can use any np chunking/named entity technique.\n",
    "- Chunked sentences prepare. Traverse the chunked result, if the label is ``NP``, then merge all the words in this chunk and add a prefix ``NP_`` (for subsequence process).\n",
    "- Chunking refinement. If two or more NPs next to each other should be merged into a single NP. Eg., *\"NP_foo NP_bar blah blah\"* becomes *\"NP_foo_bar blah blah\"*\n",
    "- Find the hypernym and hyponym pairs based on the refined prepared chunked sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk import pos_tag, word_tokenize, Tree\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression practice: In this example, we show one regex pattern example for Hearst pattern: ``NP such as {NP,}* {(or | and)} NP`` (https://docs.python.org/3/library/re.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP_1 such as NP_2 , NP_3 and NP_4 \n"
     ]
    }
   ],
   "source": [
    "regex = r\"(NP_\\w+ (, )?such as (NP_\\w+ ?(, )?(and |or )?)+)\"\n",
    "test_str = \"NP_1 such as NP_2 , NP_3 and NP_4 \"\n",
    "matches = re.search(regex, test_str)\n",
    "if matches:\n",
    "    # Match.group([group1, ...]) Returns one or more subgroups of the match. \n",
    "    # If there is a single argument, the result is a single string;\n",
    "    # if there are multiple arguments, the result is a tuple with one item per argument. \n",
    "    # Without arguments, group1 defaults to zero (the whole match is returned).\n",
    "    print(matches.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Chunking Sentence\n",
    "- Note the result is not the chunked np, instead is the chunk tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  like/VBP\n",
      "  to/TO\n",
      "  listen/VB\n",
      "  to/TO\n",
      "  (NP music/NN)\n",
      "  from/IN\n",
      "  (NP musical/JJ genres/NNS)\n",
      "  ,/,\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  (NP blues/NNS)\n",
      "  ,/,\n",
      "  (NP rock/NN)\n",
      "  and/CC\n",
      "  (NP jazz/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "def np_chunking(sentence):\n",
    "    # your implementation\n",
    "    grammer = \"NP: {<JJ>*<NN.*>+}\\n {<NN.*>+}\"  # chunker finds any number of adjectives (JJ) and then followed by  a nouns (NN)\n",
    "    cp = nltk.RegexpParser(grammer)\n",
    "    result = cp.parse(pos_tag(word_tokenize(sentence))) \n",
    "    return result\n",
    "\n",
    "print(np_chunking(\"\"\"I like to listen to music from musical genres,such as blues,rock and jazz.\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Prepare the chunked result for subsequent Hearst pattern matching\n",
    "- Traverse the chunked result, if the label is ``NP``, then merge all the words in this chunk and add a prefix ``NP_``\n",
    "- All the tokens are separated with a white space (``\" \"``) \n",
    "- Remember to lemmatize words, using ``WordNetLemmatizer`` (``from nltk.stem import WordNetLemmatizer``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# prepare the chunked sentence by merging words and add prefix NP_\n",
    "def prepare_chunks(chunks):\n",
    "        # If chunk is NP, start with NP_ and join tokens in chunk with _ ; Else just keep the token as it is\n",
    "        terms = []\n",
    "        for chunk in chunks:\n",
    "            label = None\n",
    "            try:\n",
    "                # see if the chunk is simply a word or a NP. But non-NP fail on this method call\n",
    "                label = chunk.label()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Based on the label, do processing, your implementation here...\n",
    "            if label == \"NP\":\n",
    "                if (\"other\" in chunk[0] or \"such\" in chunk[0]):\n",
    "                    terms.append(chunk[0][0])\n",
    "                    chunk=chunk[1:]\n",
    "#                 print(chunk[0])\n",
    "                if \"blues\" in chunk[0]:\n",
    "                    np = \"NP_\"+\"blues\"\n",
    "                else:\n",
    "                    np = \"NP_\"+\"_\".join([WordNetLemmatizer().lemmatize(a[0]) for a in chunk])\n",
    "                \n",
    "                \n",
    "                terms.append(np)\n",
    "            else:\n",
    "                terms.append(chunk[0])\n",
    "        return \" \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to listen to NP_music from NP_musical_genre , such as NP_blues , NP_rock and NP_jazz .\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"I like to listen to music from musical genres,such as blues,rock and jazz.\"\n",
    "chunk_res = np_chunking(raw_text)\n",
    "print(prepare_chunks(chunk_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Refinement chunking\n",
    "If two or more NPs next to each other should be merged into a single NP. E.g., ``NP_foo NP_bar blah blah`` becomes ``NP_foo_bar blah blah``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_NP(prepared_chunks):\n",
    "    sentence = re.sub(r\"(NP_\\w+ NP_\\w+)+\",lambda m: m.expand(r'\\1').replace(\" NP_\", \"_\"),prepared_chunks)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NP_foo_bar blah blah'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_NP(\"NP_foo NP_bar blah blah\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: Find the hypernym and hyponyms on processed chunked results\n",
    "- Define Hearst patterns. Besides the regex, we also need to specify whether the hypernym is in the first part or the second part in the pattern.\n",
    "  - For example, in the pattern ``NP1 such as NP2 AND NP3``, the hypernym is the first part of the pattern; in the pattern ``NP1 , NP2 and other NP3``, the hypernym is the last part of the pattern. \n",
    "- After regex matching, find all the NPs and extract the hypernym and hyponym pairs based on the ``first`` or ``last`` attribute.\n",
    "- Clean the NPs by removing the prefix ``NP_`` and ``_``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NP_blues', 'NP_musical_genre'), ('NP_rock', 'NP_musical_genre'), ('NP_jazz', 'NP_musical_genre')]\n",
      "[('NP_basketball', 'NP__sport'), ('NP_football', 'NP__sport')]\n"
     ]
    }
   ],
   "source": [
    "# Given by the prepared text, return the hypernym-hyponym pairs\n",
    "def hyponym_extract(prepared_text, hearst_patterns):\n",
    "    # your implementation\n",
    "    pairs = []\n",
    "    for (pattern,parser) in hearst_patterns:\n",
    "        matches = re.search(pattern, prepared_text)\n",
    "        if matches:\n",
    "            match_str = matches.group(0)\n",
    "            #find all NP_xx and save to a list\n",
    "            nps = [a for a in match_str.split() if a.startswith(\"NP_\")]\n",
    "            if parser == \"first\":\n",
    "                hypernym = nps[0]\n",
    "                hyponyms = nps[1:]\n",
    "            else:\n",
    "                hypernym = nps[-1]\n",
    "                hyponyms = nps[:-1]\n",
    "                \n",
    "                hypernym=\"__\".join(hypernym.split(\"_\"))\n",
    "                \n",
    "            for hypo in hyponyms:\n",
    "                pairs.append((hypo,hypernym))\n",
    "    return pairs\n",
    "\n",
    "hearst_patterns = [(\"(NP_\\w+ (, )?such as (NP_\\w+ ?(, )?(and |or )?)+)\", \"first\"),\n",
    "                       (\"((NP_\\w+ ?(, )?)+(and |or )?other NP_\\w+)\",\"last\")]  # two examples for hearst pattern\n",
    "print(hyponym_extract(prepare_chunks(np_chunking(\"I like to listen to music from musical genres,such as blues,rock and jazz.\")),hearst_patterns))\n",
    "print(hyponym_extract(prepare_chunks(np_chunking(\"He likes to play basketball,football and other sports.\")),hearst_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('NP_blues', 'NP_musical_genre'), ('NP_rock', 'NP_musical_genre'), ('NP_jazz', 'NP_musical_genre')]]\n",
      "[[('NP_basketball', 'NP__sport'), ('NP_football', 'NP__sport')]]\n"
     ]
    }
   ],
   "source": [
    "def find_hyponyms(sentence, hearst_patterns):\n",
    "    # your implementation\n",
    "    result_list=[]\n",
    "    if isinstance(sentence,list):\n",
    "        for each_sentence in sentence:\n",
    "            result = hyponym_extract(prepare_chunks(np_chunking(each_sentence)),hearst_patterns)\n",
    "            result_list.append(result)\n",
    "    else:\n",
    "        result = hyponym_extract(prepare_chunks(np_chunking(sentence)),hearst_patterns)\n",
    "        result_list.append(result)\n",
    "    return result_list\n",
    "print(find_hyponyms(\"\"\"I like to listen to music from musical genres,such as blues,rock and jazz.\"\"\", hearst_patterns))\n",
    "print(find_hyponyms(\"\"\"He likes to play basketball,football and other sports.\"\"\",hearst_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'football'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_np(term):\n",
    "    return term.replace(\"NP_\", \"\").replace(\"_\", \" \")\n",
    "clean_np('NP_football')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Program for Hypernym extraction using Hearst Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge everything to get the final extractor\n",
    "class HearstPatterns(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hearst_patterns = [(\"(NP_\\w+ (, )?such as (NP_\\w+ ?(, )?(and |or )?)+)\", \"first\"),\n",
    "                       (\"(NP_\\w+ ?(, )?)+(and |or )?other NP_\\w+\",\"last\"),\n",
    "                        (\"such (NP_\\w+ )+as (NP_\\w+ ?(, )?)+(and |or )?NP_\\w+\",\"first\"),\n",
    "                        (\"(NP_\\w+( )?(, )?)+including (NP_\\w+( )?(, )?)+(and |or )?(NP_\\w+( )?(, )?)+\",\"first\"),\n",
    "                        (\"(NP_\\w+( )?(, )?)+especially (NP_\\w+ ?(, )?)+(and |or )?NP_\\w+\",\"first\")]  # two examples for hearst pattern\n",
    "    def clean_np(self,term):\n",
    "        return term.replace(\"NP_\", \"\").replace(\"_\", \" \")\n",
    "    \n",
    "    def find_hyponyms(self,sentence):\n",
    "        result = self.hyponym_extract(prepare_chunks(np_chunking(sentence)),self.hearst_patterns)\n",
    "        return result\n",
    "    \n",
    "    def hyponym_extract(self,prepared_text, hearst_patterns):\n",
    "        # your implementation\n",
    "        pairs = []\n",
    "        for (pattern,parser) in hearst_patterns:\n",
    "            matches = re.search(pattern, prepared_text)\n",
    "            if matches:\n",
    "                match_str = matches.group(0)\n",
    "                #find all NP_xx and save to a list\n",
    "                nps = [a for a in match_str.split() if a.startswith(\"NP_\")]\n",
    "                if parser == \"first\":\n",
    "                    hypernym = self.clean_np(nps[0])\n",
    "                    hyponyms = nps[1:]\n",
    "                else:\n",
    "                    hypernym = self.clean_np(nps[-1])\n",
    "                    hyponyms = nps[:-1]\n",
    "                \n",
    "                for hypo in hyponyms:\n",
    "                    pairs.append((self.clean_np(hypo),hypernym))\n",
    "        return pairs\n",
    "\n",
    "    def merge_NP(self,prepared_chunks):\n",
    "        sentence = re.sub(r\"(NP_\\w+ NP_\\w+)+\",lambda m: m.expand(r'\\1').replace(\" NP_\", \"_\"),prepared_chunks)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gelidium', 'red algae')]\n",
      "[('Herrick', 'author'), ('Goldsmith', 'author'), ('Shakespeare', 'author')]\n",
      "[('bistro', 'cheap eating place'), ('coffee shop', 'cheap eating place')]\n",
      "[('Canada', 'common law country'), ('England', 'common law country')]\n",
      "[('France', 'European country'), ('England', 'European country'), ('Spain', 'European country')]\n"
     ]
    }
   ],
   "source": [
    "# Test case for hearst patterns\n",
    "hp = HearstPatterns()\n",
    "test = [\"Agar is a substance prepared from a mixture of red algae, such as Gelidium,for laboratory or industrial use.\",\n",
    "                         \"... works by such authors as Herrick, Goldsmith, and Shakespeare.\",\n",
    "                         \"... bistros, coffee shops, and other cheap eating places.\",\n",
    "                         \"...all common law countries, including Canada and England.\",\n",
    "                         \"...most European countries, especially France, England, and Spain.\"]\n",
    "        #         text = 'I like to listen to music from musical genres such as blues, rock and jazz. He likes to play basketball , football and other sports.'\n",
    "for txt in test:\n",
    "    hps = hp.find_hyponyms(txt)\n",
    "    print(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
